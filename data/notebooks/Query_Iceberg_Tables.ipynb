{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a86966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>namespace</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>default_database</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------------+\n",
       "|        namespace |\n",
       "+------------------+\n",
       "| default_database |\n",
       "+------------------+"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "show databases;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76af9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "use default_database;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80edb229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>namespace</th>\n",
       "            <th>tableName</th>\n",
       "            <th>isTemporary</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>default_database</td>\n",
       "            <td>customers_sink</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------------+----------------+-------------+\n",
       "|        namespace |      tableName | isTemporary |\n",
       "+------------------+----------------+-------------+\n",
       "| default_database | customers_sink |       False |\n",
       "+------------------+----------------+-------------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "show tables;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27568c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/05 04:53:48 WARN RESTSessionCatalog: Failed to report metrics to REST endpoint for table default_database.customers_sink\n",
      "org.apache.iceberg.exceptions.BadRequestException: Malformed request: No route for request: POST v1/namespaces/default_database/tables/customers_sink/metrics\n",
      "\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:152)\n",
      "\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:135)\n",
      "\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:150)\n",
      "\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:224)\n",
      "\tat org.apache.iceberg.rest.HTTPClient.post(HTTPClient.java:269)\n",
      "\tat org.apache.iceberg.rest.RESTClient.post(RESTClient.java:112)\n",
      "\tat org.apache.iceberg.rest.RESTSessionCatalog.reportMetrics(RESTSessionCatalog.java:321)\n",
      "\tat org.apache.iceberg.rest.RESTSessionCatalog.lambda$loadTable$2(RESTSessionCatalog.java:307)\n",
      "\tat org.apache.iceberg.BaseTableScan.lambda$planFiles$0(BaseTableScan.java:168)\n",
      "\tat org.apache.iceberg.io.CloseableIterable$3.close(CloseableIterable.java:95)\n",
      "\tat org.apache.iceberg.spark.source.SparkBatchQueryScan.files(SparkBatchQueryScan.java:125)\n",
      "\tat org.apache.iceberg.spark.source.SparkBatchQueryScan.tasks(SparkBatchQueryScan.java:138)\n",
      "\tat org.apache.iceberg.spark.source.SparkScan.toBatch(SparkScan.java:111)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.BatchScanExec.batch$lzycompute(BatchScanExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.BatchScanExec.batch(BatchScanExec.scala:42)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.BatchScanExec.inputPartitions$lzycompute(BatchScanExec.scala:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.BatchScanExec.inputPartitions(BatchScanExec.scala:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceV2ScanExecBase.supportsColumnar(DataSourceV2ScanExecBase.scala:142)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceV2ScanExecBase.supportsColumnar$(DataSourceV2ScanExecBase.scala:141)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.BatchScanExec.supportsColumnar(BatchScanExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.apply(DataSourceV2Strategy.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$1(QueryPlanner.scala:63)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:69)\n",
      "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:78)\n",
      "\tat scala.collection.TraversableOnce$folder$1.apply(TraversableOnce.scala:196)\n",
      "\tat scala.collection.TraversableOnce$folder$1.apply(TraversableOnce.scala:194)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n",
      "\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n",
      "\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n",
      "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:75)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:69)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.createSparkPlan(QueryExecution.scala:459)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$sparkPlan$1(QueryExecution.scala:145)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:145)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:138)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executedPlan$1(QueryExecution.scala:158)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:158)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:151)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.simpleString(QueryExecution.scala:204)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$explainString(QueryExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.explainString(QueryExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3685)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>database_name</th>\n",
       "            <th>table_name</th>\n",
       "            <th>id</th>\n",
       "            <th>first_name</th>\n",
       "            <th>last_name</th>\n",
       "            <th>email</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>inventory</td>\n",
       "            <td>customers</td>\n",
       "            <td>1001</td>\n",
       "            <td>Sally</td>\n",
       "            <td>Thomas</td>\n",
       "            <td>sally.thomas@acme.com</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>inventory</td>\n",
       "            <td>customers</td>\n",
       "            <td>1002</td>\n",
       "            <td>George</td>\n",
       "            <td>Bailey</td>\n",
       "            <td>gbailey@foobar.com</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>inventory</td>\n",
       "            <td>customers</td>\n",
       "            <td>1003</td>\n",
       "            <td>Edward</td>\n",
       "            <td>Walker</td>\n",
       "            <td>ed@walker.com</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>inventory</td>\n",
       "            <td>customers</td>\n",
       "            <td>1004</td>\n",
       "            <td>Anne</td>\n",
       "            <td>Kretchmar</td>\n",
       "            <td>annek@noanswer.org</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+------+------------+-----------+-----------------------+\n",
       "| database_name | table_name |   id | first_name | last_name |                 email |\n",
       "+---------------+------------+------+------------+-----------+-----------------------+\n",
       "|     inventory |  customers | 1001 |      Sally |    Thomas | sally.thomas@acme.com |\n",
       "|     inventory |  customers | 1002 |     George |    Bailey |    gbailey@foobar.com |\n",
       "|     inventory |  customers | 1003 |     Edward |    Walker |         ed@walker.com |\n",
       "|     inventory |  customers | 1004 |       Anne | Kretchmar |    annek@noanswer.org |\n",
       "+---------------+------------+------+------------+-----------+-----------------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from customers_sink;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba9d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
